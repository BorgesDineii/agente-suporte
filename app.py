import streamlit as st
import requests
from google import genai # Mudan√ßa para o import correto
import os
from bs4 import BeautifulSoup
import base64
import json
import numpy as np # Adicionado
import faiss # Adicionado
from langchain_text_splitters import RecursiveCharacterTextSplitter # Adicionado

# --- 1. CONFIGURA√á√ïES E VARI√ÅVEIS ---
# ATEN√á√ÉO: √â recomendado usar st.secrets ou vari√°veis de ambiente para estas chaves.
# Deixei como vari√°veis diretas para fins de restaura√ß√£o, mas remova antes de fazer commit!
api_key = "xxxx"
ATLASSIAN_USER = "valdinei.borges@e-deploy.com.br"
ATLASSIAN_TOKEN = "xxxx-HeQXotkpCj3tN1LzABhvv0MaI2GkZqDoTII98=FA994E2B"
CONFLUENCE_URL = "https://edeploy.atlassian.net"

CONFLUENCE_URL = "https://edeploy.atlassian.net"
USER_EMAIL = "valdinei.borges@e-deploy.com.br"
API_TOKEN = "xxx-HeQXotkpCj3tN1LzABhvv0MaI2GkZqDoTII98=FA994E2B"
SPACE_KEY = "SPOS2"

if not all([CONFLUENCE_URL, USER_EMAIL, API_TOKEN]):
    st.error("ERRO: Configure as variaveis de ambiente (ATLASSIAN_USER, ATLASSIAN_TOKEN e CONFLUENCE_URL).")
    st.stop()

# Inicializa√ß√£o do cliente Gemini
try:
    client = genai.Client(api_key=api_key)
except Exception as e:
    st.error(f"Erro ao iniciar o cliente Google GenAI: {e}")
    st.stop()


# --- 2. FUN√á√ïES DE INGEST√ÉO E LIMPEZA DE DADOS ---

def get_auth_headers():
    """
    Cria um cabe√ßalho de autentica√ß√£o (Basic Auth).
    """
    auth_string = f"{USER_EMAIL}:{API_TOKEN}"
    encoded_auth = base64.b64encode(auth_string.encode()).decode()
    return{
        "Authorization": f"Basic {encoded_auth}",
        "Accept":"application/json"
    }

def limpando_html_content(html_content):
    """
    Remove tags HTML e limpa o texto do conteudo do Confluence.
    """
    soup = BeautifulSoup(html_content, 'html.parser')

    for tag in soup(["nav", "header", "footer", "style", "script"]):
        tag.decompose()

    return soup.get_text(separator=' ', strip=True)

def busca_conteudo_confluence(space_key):
    """
    Busca todas as p√°ginas de um Space Key e extrai o conte√∫do limpo.
    """
    # Usando o m√©todo mais robusto (auth=(email, token)) para evitar problemas de Base64
    auth_credentials = (USER_EMAIL.strip(), API_TOKEN.strip()) 
    headers = {"Accept":"application/json"}
    
    url = f"{CONFLUENCE_URL}/wiki/rest/api/content?spaceKey={space_key}&expand=body.storage&limit=25"
    clean_knowledge_base = []

    try:
        # CORRE√á√ÉO: Usando 'auth' no requests para autentica√ß√£o direta
        response = requests.get(url, headers=headers, auth=auth_credentials) 
        response.raise_for_status()

        data = response.json()
        st.success(f"‚úÖ Conectado ao Confluence. Encontradas {len(data.get('results',[]))} p√°ginas.")
        
        for page in data.get('results', []):
            title = page.get('title')
            html_content = page.get('body', {}).get('storage', {}).get('value', '')

            if html_content:
                # CORRE√á√ÉO: Alterando a chamada da fun√ß√£o para 'limpando_html_content'
                clean_text = limpando_html_content(html_content) 
                clean_knowledge_base.append({
                    "title":title,
                    "text":clean_text
                })
        return clean_knowledge_base

    except requests.exceptions.HTTPError as e:
        st.error(f"‚ùå Erro HTTP ao conectar: {e}. Verifique seu Token.")
        return None
    except Exception as e:
        st.error(f"‚ùå Erro desconhecido: {e}")
        return None
        
def create_vector_store(knowledge_base, client):
    """
    Divide o texto em chunks, gera embeddings e cria o √≠ndice vetorial FAISS.
    """
    documents = []
    
    # 1. Chunking (Divis√£o do texto)
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200, 
        length_function=len 
    )

    for item in knowledge_base:
        chunks = text_splitter.split_text(item['text'])
        for chunk in chunks:
            documents.append({
                "title": item['title'],
                "chunk": chunk,
                "text": chunk 
            })
    
    # 2. Embedding (Gera√ß√£o de Vetores)
    texts = [doc["text"] for doc in documents]
    
    try:
        response = client.models.embed_content(
            model='text-embedding-004', 
            contents=texts 
        )

        raw_embeddings_list = [item.values for item in response.embeddings]

        # CORRE√á√ÉO APLICADA AQUI: Nota√ß√£o de Ponto
        embeddings = np.array(raw_embeddings_list, dtype=np.float32)

        if embeddings.ndim == 1:
            embeddings = embeddings.reshape(1, -1)

    except Exception as e:
        st.error(f"‚ùå Erro no Embedding do Gemini: {e}")
        return None, None

    # 3. FAISS (Cria√ß√£o do √çndice Vetorial)
    d = embeddings.shape[1]
    index = faiss.IndexFlatL2(d)
    index.add(embeddings)

    return index, documents


# --- 3. FUN√á√ÉO DE RESPOSTA RAG ---

def gerar_resposta_rag(user_query, vector_index, documents, client):
    """
    Busca o contexto relevante no √≠ndice FAISS e usa o Gemini para gerar uma resposta.
    """
    # 1. Recupera√ß√£o (Retrieval)
    
    # Cria o embedding da pergunta do usu√°rio
    query_embedding_response = client.models.embed_content(
        model='text-embedding-004',
        contents=[user_query]
    )

    raw_query_vector = query_embedding_response.embeddings[0].values

    # CORRE√á√ÉO APLICADA AQUI: Nota√ß√£o de Ponto
    query_embedding = np.array(raw_query_vector, dtype=np.float32)

    # Busca os 3 chunks mais relevantes
    D, I = vector_index.search(query_embedding.reshape(1, -1), k=3) 
    
    # Constr√≥i o contexto com o texto dos chunks recuperados
    retrieved_texts = [documents[i]['text'] for i in I[0] if i != -1]
    
    if not retrieved_texts:
        return "Desculpe meu nobre, n√£o encontrei informa√ß√µes relevantes na Base de Conhecimento de Suporte"

    context = "\n---\n".join(retrieved_texts)

    # 2. Prompt Engineering
    system_instruction = (
    """
        O Agente de Suporte √© um chatbot formal, objetivo e preciso, criado para auxiliar na resolu√ß√£o de problemas internos utilizando exclusivamente informa√ß√µes verificadas na Base de Conhecimento (Confluence), chamados, NDP (Novas Deamandas POS), OXAP (Opera√ß√µes x Atendimentos x Produtos) e tickets existentes na plataforma Jira.
   
    üîπ Regras Gerais de Atendimento
    1. Pergunta inicial obrigat√≥ria
    Antes de qualquer resposta, sempre pergunte ao usu√°rio:
    "Qual sistema voc√™ est√° se referindo? MWPOS ou 3S?"
    
    2. Associa√ß√£o de sistemas
    - MWPOS / MWPOS_KDS ‚Üí Utilizado apenas em lojas BK e BKF.
    - 3S Checkout ‚Üí Utilizado por todas as demais lojas.

    3. Fontes de informa√ß√£o
    - Procedimentos ‚Üí Localizados no Confluence.
    - Tickets de desenvolvimento ‚Üí OXAP e NDP (n√£o s√£o procedimentos, mas podem conter erros e corre√ß√µes relevantes ao problema informado pelo usu√°rio).
    - Chamados ‚Üí Consultar no Jira para localizar casos semelhantes.

    4. Mem√≥ria de conversa
    - Armazenar e manter contexto para que seja poss√≠vel continuar a conversa de onde parou.
    - Retomar pesquisas ou tickets j√° consultados durante a intera√ß√£o.

    ---

    üîπ Fun√ß√µes e Responsabilidades

    1. Consulta ao Confluence
    - Pesquisar e apresentar apenas procedimentos oficiais.
    - Fornecer instru√ß√µes passo a passo com clareza.
    - Sempre que poss√≠vel, incluir links diretos para documentos, manuais e anexos.

    2. Vincula√ß√£o de Chamados
    - Procurar chamados anteriores com problemas semelhantes.
    - Apresentar a solu√ß√£o adotada e o n√∫mero/ticket para refer√™ncia.

    3. Integra√ß√£o com OXAP e NDP
    - Localizar OXAPs e NDPs relacionados ao problema.
    - Analisar o conte√∫do, n√£o apenas o t√≠tulo, para compreender erros e corre√ß√µes.
    - Exibir o resumo ou conte√∫do completo, quando necess√°rio.
    - estar sempre atualizado referente a OXAP e NDP do jira.

    4. An√°lise de Erros e Problemas Recorrentes
    - Identificar erros j√° registrados em chamados, OXAPs ou NDPs anteriores.
    - Informar a causa prov√°vel e o procedimento adotado para corre√ß√£o.
    - Garantir que a solu√ß√£o seja comunicada para manter todos cientes.

    ---

    üîπ Padr√£o de Resposta
    - Linguagem: Formal, clara e sem g√≠rias.
    - Estrutura:
    1. Descri√ß√£o do problema
    2. Poss√≠veis causas
    3. Passo a passo da solu√ß√£o
    4. Links/documentos de apoio
    - Quando n√£o encontrar solu√ß√£o:
    Informar que n√£o foi localizado nenhum procedimento e que a quest√£o ser√° encaminhada ao setor respons√°vel.

    ---

    üîπ Restri√ß√µes Importantes
    - N√£o inventar procedimentos ou informa√ß√µes.
    - Utilizar apenas conte√∫do da base oficial (Confluence, Jira, OXAP, NDP).
    - Sempre tentar localizar chamado ou ticket similar antes de responder que n√£o h√° solu√ß√£o.

    ---

    üîπ Op√ß√£o de Melhoria
    Caso o assistente n√£o encontre a resposta correta ou n√£o localize um procedimento aplic√°vel, ele deve informar ao usu√°rio o seguinte:
    "N√£o encontrei um procedimento ou solu√ß√£o para este caso. Por favor, entre em contato com [Seu Nome] pelo Microsoft Teams para que possamos criar, corrigir ou atualizar um procedimento para consultas futuras.
    """)

    prompt = (
        f"INSTRU√á√ÉO: {system_instruction}\n\n"
        f"CONTEXTO DE PROCEDIMENTO:\n{context}\n\n"
        f"PERGUNTA DO USU√ÅRIO: {user_query}"
    )

    # 3. Gera√ß√£o
    response = client.models.generate_content(
        model='gemini-2.5-flash',
        contents=prompt
    )
    return response.text

# --- 4. L√ìGICA PRINCIPAL DO STREAMLIT ---

st.set_page_config(
    page_title="Agente de Suporte para procedimento e corre√ß√£o de problemas relacionados ao sistema",
    layout="wide"
)

st.title("Agente de Suporte (Rodrigo GPTü§ìüêã)")
st.markdown("Ol√°!! Sou seu Rodrigo GPT, seu assistente de suporte para consulta de d√∫vidas e procedimento.")
st.markdown("---")

# Removendo st.text_area isolado, pois a entrada de chat √© mais eficiente

# Fun√ß√£o get_respondendo_pergunta removida pois n√£o era usada

if 'vector_index' not in st.session_state:
    # 1. INGEST√ÉO/CARREGAMENTO
    with st.spinner("‚è≥ Carregando ou Ingerindo Base de Conhecimento do Confluence..."):
        
        knowledge_base = busca_conteudo_confluence(SPACE_KEY)
        
        if knowledge_base:
            try:
                vector_index, documents = create_vector_store(knowledge_base, client)
                
                st.session_state['vector_index'] = vector_index
                st.session_state['documents'] = documents
                st.success("‚úÖ Base de Conhecimento Carregada com Sucesso!")
            
            except Exception as e:
                st.error(f"‚ùå Erro fatal durante o Embedding ou FAISS: {e}")
                st.stop()
        else:
            st.error("‚ùå Erro fatal: N√£o foi poss√≠vel carregar o conte√∫do do Confluence.")
            st.stop()

# Garante que as vari√°veis estejam dispon√≠veis
vector_index = st.session_state['vector_index']
documents = st.session_state['documents']

# 2. L√ìGICA DO CHAT

if "messages" not in st.session_state:
    st.session_state.messages = []

# Exibe o hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Captura a entrada do usu√°rio
if prompt := st.chat_input("Pergunte sobre um procedimento ou erro..."):
    
    # CORRE√á√ÉO: st.session_state.messages.append
    st.session_state.messages.append({"role": "user", "content": prompt}) 
    
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.spinner("ü§ñ Buscando e analisando procedimentos..."):
        try:
            full_response = gerar_resposta_rag(prompt, vector_index, documents, client)
        except Exception as e:
            full_response = f"Ocorreu um erro ao gerar a resposta: {e}"

    with st.chat_message("assistant"):
        st.markdown(full_response)
        st.session_state.messages.append({"role": "assistant", "content": full_response})


# O bloco 'if __name__ == "__main__":' foi removido e sua l√≥gica integrada ao Streamlit.
# A fun√ß√£o de chat do Streamlit j√° √© o bloco principal de execu√ß√£o.